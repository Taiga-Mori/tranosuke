import os
import streamlit as st
from pathlib import Path
import yaml

from init import *
from utils import *
from wav import *
from utterance import *
from morpheme import *
from phoneme import *
from word import *



def main():

    # ã‚¢ãƒ—ãƒªã‚¿ã‚¤ãƒˆãƒ«ã®è¡¨ç¤º
    st.title("æ›¸ãèµ·ã“ã—ã‚¢ãƒ—ãƒª ã¨ã‚‰ã®ã™ã‘")

    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    tranosuke = BASE_PATH / "asset/tranosuke.png"  # ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸
    tranosuke_greeting = BASE_PATH / "asset/tranosuke_greeting.png"  # ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸
    tranosuke_transcribing = BASE_PATH / "asset/tranosuke_transcribing.png"  # å‡¦ç†ä¸­ã‚¤ãƒ¡ãƒ¼ã‚¸
    tranosuke_confusing = BASE_PATH / "asset/tranosuke_confusing.png"  # å‡¦ç†ä¸­ã‚¤ãƒ¡ãƒ¼ã‚¸
    tranosuke_finish = BASE_PATH / "asset/tranosuke_finish.png"  # å®Œäº†ã‚¤ãƒ¡ãƒ¼ã‚¸

    # ç”»åƒè¡¨ç¤ºç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€
    img_placeholder = st.empty()
    img_placeholder.image(tranosuke)



    # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
    # init = åˆå›èµ·å‹•æ™‚ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸­ã«hugging faceã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒãªã„å ´åˆï¼‰
    # start = åˆæœŸçŠ¶æ…‹
    # processing = å‡¦ç†ä¸­
    # error = ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚
    # done = å®Œäº†æ™‚

    if "state" not in st.session_state:
        st.session_state.state = None

    # é–‹å§‹ç”»é¢
    if st.session_state.state is None:
        col1, col2 = st.columns(2)

        with col1:
            first_time = st.button("ã¯ã˜ã‚ã¦")

        with col2:
            not_first_time = st.button("ã¯ã˜ã‚ã¦ã˜ã‚ƒãªã„")

        if first_time:
            st.session_state.state = "init"
            st.rerun()
            
        elif not_first_time:
            st.session_state.state = "start"
            st.rerun()



    # --- initã‚»ãƒƒã‚·ãƒ§ãƒ³ ---
    if st.session_state.state == "init":
        img_placeholder.image(tranosuke_greeting)

        # åˆæœŸåŒ–
        initialize()

        # ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—
        st.markdown("""ã¨ã‚‰ã®ã™ã‘ã‚’ä½¿ã£ã¦ãã‚Œã¦ã‚ã‚ŠãŒã¨ã†ï¼ã“ã®ã‚¢ãƒ—ãƒªã§ã¯è©±è€…åˆ†é›¢ã«pyannoteã‚’ä½¿ã£ã¦ã„ã¦ã€ãã®ãŸã‚ã«Hugging Faceã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒã„ã‚‹ã‚ˆï¼
1. [Hugging Face](https://huggingface.co)ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã—ã¦ã­  
2. pyannoteã®[åˆ©ç”¨è¦ç´„](https://hf.co/pyannote/speaker-diarization-community-1)ã«åŒæ„ã—ã¦ã­  
3. ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’[ç™ºè¡Œ](https://hf.co/settings/tokens)ã—ã¦ã­ï¼ˆä¸€ç•ªä¸Šã®Token typeã§Readã‚’é¸ã‚“ã§ã­ï¼‰  
4. ä½œæˆã—ãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä¸‹ã«å…¥åŠ›ã—ã¦ã­ï¼""")
        HUGGINGFACE_ACCESS_TOKEN = st.text_input("ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³")
        if st.button("ä¿å­˜"):
            if HUGGINGFACE_ACCESS_TOKEN:
                # config èª­ã¿è¾¼ã¿
                if CONFIG_PATH.exists():
                    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
                        config = yaml.safe_load(f) or {}
                else:
                    config = {}

                # æ›´æ–°
                config["HUGGINGFACE_ACCESS_TOKEN"] = HUGGINGFACE_ACCESS_TOKEN

                # ä¿å­˜
                with open(CONFIG_PATH, "w", encoding="utf-8") as f:
                    yaml.safe_dump(config, f, allow_unicode=True, sort_keys=False)

                st.success("ä¿å­˜ã—ã¾ã—ãŸï¼")
                st.session_state.state = "start"
                st.rerun()



    # --- startã‚»ãƒƒã‚·ãƒ§ãƒ³ ---
    elif st.session_state.state == "start":
        img_placeholder.image(tranosuke)

        # --- å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ  ---
        st.session_state.audio_path  = Path(st.text_input("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã©ã“ï¼Ÿ", "ä¾‹. /Users/username/audio.wav"))
        st.session_state.quality = st.radio("ã©ã£ã¡ãŒã„ã„ï¼Ÿ", ["ã‚¹ãƒ”ãƒ¼ãƒ‰å„ªå…ˆ!", "ã‚¯ã‚ªãƒªãƒ†ã‚£å„ªå…ˆ!"])

        # --- è§£æãƒœã‚¿ãƒ³ ---
        if st.button("æ›¸ãèµ·ã“ã—å®Ÿè¡Œï¼"):
            # å‡¦ç†ä¸­ç”»åƒã«åˆ‡ã‚Šæ›¿ãˆ
            st.session_state.state = "processing"
            st.rerun()
    


    # --- processingã‚»ãƒƒã‚·ãƒ§ãƒ³ ---
    elif st.session_state.state == "processing":
        try:
            img_placeholder.image(tranosuke_transcribing)

            # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ
            st.session_state.output_dir = st.session_state.audio_path.with_suffix("")
            if not os.path.exists(st.session_state.output_dir):
                os.makedirs(st.session_state.output_dir)

            

            # --- wavã«å¤‰æ› ---
            with st.spinner("wavãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ã—ã¦ã‚‹ã‚ˆğŸŒŠ"):
                st.session_state.wav_path = st.session_state.output_dir / f"{st.session_state.audio_path.stem}_processed.wav"
                convert_to_mono_wav(
                    st.session_state.audio_path,
                    st.session_state.wav_path
                    )
                


            # --- æ›¸ãèµ·ã“ã— ---
            with st.spinner("ç™ºè©±ã‚’æ›¸ãèµ·ã“ã—ã¦ã‚‹ã‚ˆâœï¸"):
                if st.session_state.quality == "ã‚¹ãƒ”ãƒ¼ãƒ‰å„ªå…ˆ":
                    model_name = "turbo"
                    beam_size = 5
                else:
                    model_name = "large-v3"
                    beam_size = 10

                df_utt = transcribe_utterance(
                    audio_path=st.session_state.wav_path,
                    model_name=model_name,
                    beam_size=beam_size
                    )
                
                if len(df_utt) == 0:
                    raise ValueError("ç™ºè©±ãŒä¸€ã¤ã‚‚æ¤œå‡ºã§ããªã‹ã£ãŸã‚ˆï¼")
                


            # --- å½¢æ…‹ç´ è§£æ ---
            with st.spinner("å½¢æ…‹ç´ è§£æã‚’ã—ã¦ã‚‹ã‚ˆğŸ“•"):
                df_morph = morph_analyze(df_utt)

                # ãƒãƒ¼ã‚ºè¨˜å·ã®è¡Œã‚’å‰Šé™¤
                df_morph_cleaned = df_morph.copy()
                df_morph_cleaned = df_morph_cleaned[df_morph_cleaned["orth"] != "Â¥"]



            # --- å¼·åˆ¶ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆ ---
            with st.spinner("å¼·åˆ¶ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã‚’ã—ã¦ã‚‹ã‚ˆğŸ”"):
                df_phon = forced_align(st.session_state.wav_path, df_utt, df_morph, 3)
                df_phon.to_csv(st.session_state.output_dir / "phoneme.csv", encoding="utf-8_sig", index=None)



            # --- ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã®çµæœã‚’ã‚‚ã¨ã«å˜èªã«ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’è¿½åŠ ã—ç™ºè©±ã®é–‹å§‹çµ‚äº†æ™‚é–“ã‚’ä¿®æ­£ ---
            with st.spinner("å˜èªã«ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’è¿½åŠ ã—ã¦ã‚‹ã‚ˆâ°"):
                df_word = add_word_segment(df_morph_cleaned, df_phon)
                df_word.to_csv(st.session_state.output_dir / "word.csv", encoding="utf-8_sig", index=None)
            
                # ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã®çµæœã‚’ã‚‚ã¨ã«ç™ºè©±ã®é–‹å§‹æ™‚é–“ã‚’ä¿®æ­£
                df_utt_adj = adjust_utterance_time(df_utt, df_phon)
                df_utt_adj["utterance"] = df_utt_adj["utterance"].str.replace("Â¥", "")
                df_utt_adj.to_csv(st.session_state.output_dir / "utterance.csv", encoding="utf-8_sig", index=None)

            st.session_state.state = "done"
            st.rerun()
        
        # ã‚¨ãƒ©ãƒ¼ãŒèµ·ããŸå ´åˆ
        except Exception as e:
            st.session_state.error_message = e
            st.session_state.state = "error"
            st.rerun()



    # --- ã‚¨ãƒ©ãƒ¼ç”»é¢ ---
    elif st.session_state.state == "error":
        img_placeholder.image(tranosuke_confusing)
        if st.session_state.error_message:
            st.write(f"ã‚¨ãƒ©ãƒ¼ãŒèµ·ããŸã‚ˆï¼\n{st.session_state.error_message}")
        if st.button("æœ€åˆã«æˆ»ã‚‹ï¼"):
                st.session_state.state = "start"
                st.rerun()

                

    # --- å®Œäº†ç”»é¢ ---
    elif st.session_state.state == "done":
        img_placeholder.image(tranosuke_finish)
        st.success(f"çµ‚ã‚ã£ãŸã‚ˆï¼ çµæœã‚’ {st.session_state.output_dir} ã«ä¿å­˜ã—ãŸã‹ã‚‰ç¢ºèªã—ã¦ã­ï¼")

        if st.button("æ¬¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãèµ·ã“ã™!"):
            st.session_state.state = "start"
            st.rerun()



if __name__ == "__main__":
    main()